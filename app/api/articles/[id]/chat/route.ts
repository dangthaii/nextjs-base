import { NextRequest, NextResponse } from "next/server";
import { getServerSession } from "@/utils/auth";
import { prisma } from "@/lib/prisma";
import { createGeminiStream } from "@/lib/gemini";

interface Message {
  role: "user" | "assistant";
  content: string;
}

export async function POST(
  request: NextRequest,
  { params }: { params: { id: string } }
) {
  try {
    const session = await getServerSession();
    const userId = session?.user?.id;

    if (!userId) {
      return NextResponse.json({ message: "Unauthorized" }, { status: 401 });
    }

    const { id: articleId } = await params;
    const body = await request.json();
    const { messages } = body as { messages?: Message[] };

    if (!messages || messages.length === 0) {
      return NextResponse.json(
        { message: "Messages are required" },
        { status: 400 }
      );
    }

    // Verify the article exists and user has access to it
    const article = await prisma.article.findUnique({
      where: { id: articleId },
    });

    if (!article) {
      return NextResponse.json(
        { message: "Article not found" },
        { status: 404 }
      );
    }

    // Check if the article belongs to the user or has public access
    const hasAccess =
      article.authorId === userId ||
      (article as any).isPublic ||
      (article as any).sharedWithUserIds?.includes(userId);

    if (!hasAccess) {
      return NextResponse.json(
        { message: "You don't have access to this article" },
        { status: 403 }
      );
    }

    // Build a conversation prompt from the history
    const historyPrompt = messages
      .map(
        (m) => `${m.role === "user" ? "NgÆ°á»i dÃ¹ng" : "Trá»£ lÃ½"}: ${m.content}`
      )
      .join("\n");

    const prompt = `Báº¡n lÃ  trá»£ lÃ½ AI thÃ¢n thiá»‡n, hÃ i hÆ°á»›c vÃ  giÃ u nÄƒng lÆ°á»£ng.\n- LuÃ´n tráº£ lá»i báº±ng tiáº¿ng Viá»‡t rÃµ rÃ ng, sÃºc tÃ­ch.\n- CÃ³ thá»ƒ sá»­ dá»¥ng markdown, bullet list, vÃ  icon cáº£m xÃºc (vÃ­ dá»¥: ğŸ˜€ğŸ˜‰ğŸ”¥ğŸ’¡ğŸš€) Ä‘á»ƒ lÃ m cÃ¢u tráº£ lá»i sinh Ä‘á»™ng vÃ  vui váº».\n- Tuyá»‡t Ä‘á»‘i KHÃ”NG sá»­ dá»¥ng dáº¥u gáº¡ch ngang \"---\" lÃ m phÃ¢n cÃ¡ch.\n\nCuá»™c há»™i thoáº¡i:\n${historyPrompt}\nTrá»£ lÃ½:`;

    const stream = await createGeminiStream(prompt, {
      model: "gemini-2.5-flash",
    });

    return new Response(stream, {
      headers: {
        "Content-Type": "application/x-ndjson",
        "Cache-Control": "no-cache",
      },
    });
  } catch (error) {
    console.error("Error in streaming chat:", error);
    return NextResponse.json(
      { message: "Failed to generate chat reply" },
      { status: 500 }
    );
  }
}
